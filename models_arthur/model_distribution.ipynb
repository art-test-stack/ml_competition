{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get most important features distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import utils\n",
    "import model_distributions as md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md.subplot_normal_distrib()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_a, train_b, train_c, X_train_estimated_a, X_train_estimated_b, X_train_estimated_c, X_train_observed_a, X_train_observed_b, X_train_observed_c, X_test_estimated_a, X_test_estimated_b, X_test_estimated_c = utils.read_files(diff_path='../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tr_a_ = {}\n",
    "train_a_mn = train_a.rename(columns={'time': 'ds', 'pv_measurement': 'y'})[:29667] # 29667\n",
    "mean_norm, std_norm = train_a_mn[\"y\"].mean(), train_a_mn[\"y\"].std()\n",
    "train_a_mn[\"y\"] = (train_a_mn[\"y\"] - train_a_mn[\"y\"].mean()) / train_a_mn[\"y\"].std()\n",
    "for h in range(24):\n",
    "    hour = f\"0{h}\" if h < 10 else str(h)\n",
    "    y_tr_a_[h] = train_a_mn[train_a_mn['ds'].dt.strftime('%H:%M:%S').str.endswith(f'{hour}:00:00')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = utils.get_most_important_keys()\n",
    "keys.remove('date_forecast') if 'date_forecast' in keys else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_a['time'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summer_dates(df):\n",
    "    result = df > '2019-04-30' and df < \"2019-09-20\"\n",
    "    result += df > '2020-04-30' and df < \"2020-09-20\"\n",
    "    result += df > '2021-04-30' and df < \"2021-09-20\"\n",
    "    result += df > '2022-04-30' and df < \"2022-09-20\"\n",
    "    result += df > '2023-04-30' and df < \"2023-09-20\"\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_a_mn[(train_a_mn['ds'] > '2019-04-30') & (train_a_mn['ds'] < \"2019-09-20\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tr_a_ = {}\n",
    "train_a_mn = train_a.rename(columns={'time': 'ds', 'pv_measurement': 'y'})[:29667] # 29667\n",
    "mean_norm, std_norm = train_a_mn[\"y\"].mean(), train_a_mn[\"y\"].std()\n",
    "train_a_mn[\"y\"] = (train_a_mn[\"y\"] - train_a_mn[\"y\"].mean()) / train_a_mn[\"y\"].std()\n",
    "for h in range(24):\n",
    "    hour = f\"0{h}\" if h < 10 else str(h)\n",
    "    y_tr_a_[h] = train_a_mn[\n",
    "        (train_a_mn['ds'].dt.strftime('%H:%M:%S').str.endswith(f'{hour}:00:00')) \n",
    "        & ( \n",
    "            ((train_a_mn['ds'] > '2019-04-30') & (train_a_mn['ds'] < \"2019-09-20\")) |\n",
    "            ((train_a_mn['ds'] > '2020-04-30') & (train_a_mn['ds'] < \"2020-09-20\")) |\n",
    "            ((train_a_mn['ds'] > '2021-04-30') & (train_a_mn['ds'] < \"2021-09-20\")) |\n",
    "            ((train_a_mn['ds'] > '2022-04-30') & (train_a_mn['ds'] < \"2022-09-20\")) \n",
    "        )\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y_tr_a_[12]['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_12_tr = (y_tr_a_[12]['y'] - y_tr_a_[12]['y'].mean() )/ y_tr_a_[12]['y'].std()\n",
    "md.plot_normal_distribution(y_12_tr, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr_obs_a_ = {}\n",
    "# columns_to_drop = [ c for c in df_normalized.columns if (c not in keys) and (c != time_column)]\n",
    "X_tr_obs_a = md.normalize_df(X_train_observed_a, keys, 'date_forecast')\n",
    "for h in range(24):\n",
    "    hour = f\"0{h}\" if h < 10 else str(h)\n",
    "    X_tr_obs_a_[h] = X_tr_obs_a[(\n",
    "        X_tr_obs_a['date_forecast'].dt.strftime('%H:%M:%S').str.endswith(f'{hour}:00:00')) \n",
    "        & ( \n",
    "            ((X_tr_obs_a['date_forecast'] > '2019-04-30') & (X_tr_obs_a['date_forecast'] < \"2019-09-20\")) |\n",
    "            ((X_tr_obs_a['date_forecast'] > '2020-04-30') & (X_tr_obs_a['date_forecast'] < \"2020-09-20\")) |\n",
    "            ((X_tr_obs_a['date_forecast'] > '2021-04-30') & (X_tr_obs_a['date_forecast'] < \"2021-09-20\")) |\n",
    "            ((X_tr_obs_a['date_forecast'] > '2022-04-30') & (X_tr_obs_a['date_forecast'] < \"2022-09-20\")) \n",
    "        )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_te_est_a_ = {}\n",
    "# columns_to_drop = [ c for c in df_normalized.columns if (c not in keys) and (c != time_column)]\n",
    "\n",
    "X_te_est_a = md.normalize_df(X_test_estimated_a, keys, 'date_forecast')\n",
    "keys = utils.get_most_important_keys()\n",
    "for h in range(24):\n",
    "    hour = f\"0{h}\" if h < 10 else str(h)\n",
    "    X_te_est_a_[h] = X_te_est_a[(\n",
    "        X_te_est_a['date_forecast'].dt.strftime('%H:%M:%S').str.endswith(f'{hour}:00:00'))\n",
    "        & (\n",
    "            ((X_te_est_a['date_forecast'] > '2023-04-30') & (X_te_est_a['date_forecast'] < \"2023-09-20\"))\n",
    "        )][keys]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adapt_Xte_to_fit_Xtr(dframe = X_test_estimated_a, diff_path: str='../', date_key = 'date_forecast'):\n",
    "    # dframe = pd.read_parquet(diff_path + settings.A.X_test_estimated) if dframe is None else dframe\n",
    "    days = []\n",
    "    for k in range(1, 31):\n",
    "        k0  = f'0{k}' if k < 10 else str(k)\n",
    "        k01 = f'0{k + 1}' if k < 9 else str(k + 1)\n",
    "        if np.array(dframe[(dframe[date_key] > f'2023-05-{k0}') & (dframe[date_key] < f'2023-05-{k01}')]).shape[0] == 0:\n",
    "            days.append(f'2023-05-{k0}')\n",
    "    if np.array(dframe[(dframe[date_key] > f'2023-05-31') & (dframe[date_key] < f'2023-06-01')]).shape[0] == 0: days.append('2023-05-31')\n",
    "    for k in range(1, 30):\n",
    "        k0  = f'0{k}' if k < 10 else str(k)\n",
    "        k01 = f'0{k + 1}' if k < 9 else str(k + 1)\n",
    "        if np.array(dframe[(dframe[date_key] > f'2023-06-{k0}') & (dframe[date_key] < f'2023-06-{k01}')]).shape[0] == 0:\n",
    "            days.append(f'2023-06-{k0}')\n",
    "    if np.array(dframe[(dframe[date_key] > f'2023-06-30') & (dframe[date_key] < f'2023-07-01')]).shape[0] == 0: days.append('2023-06-30')\n",
    "    for k in range(1, 15):\n",
    "        k0  = f'0{k}' if k < 10 else str(k)\n",
    "        k01 = f'0{k + 1}' if k < 9 else str(k + 1)\n",
    "        if np.array(dframe[(dframe[date_key] > f'2023-07-{k0}') & (dframe[date_key] < f'2023-07-{k01}')]).shape[0] == 0:\n",
    "            days.append(f'2023-07-{k0}')\n",
    "    return days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_format = '%Y-%m-%d %H:%M:%S'\n",
    "\n",
    "days_to_fit = adapt_Xte_to_fit_Xtr()\n",
    "for h in range(24):\n",
    "    days_known = utils.get_days_to_predict()\n",
    "    last_day_known = days_known[0]\n",
    "    next_day_known = days_known[1]\n",
    "    hour = f\"0{h}\" if h < 10 else str(h)\n",
    "    next_index = 1\n",
    "    last_values = (X_te_est_a_[h][X_te_est_a_[h]['date_forecast'] == f'{last_day_known} {hour}:00:00'][keys]).copy()\n",
    "    # print('last values\\n', last_values)\n",
    "    for d in days_to_fit:\n",
    "        last_values['date_forecast'] = pd.to_datetime(f'{d} {hour}:00:00')\n",
    "        if d > next_day_known:\n",
    "            next_index += 1\n",
    "            last_day_known = next_day_known\n",
    "            next_day_known = days_known[next_index] if next_index < len(days_known) - 1 else days_known[len(days_known) - 1]\n",
    "            last_values = (X_te_est_a_[h][X_te_est_a_[h]['date_forecast'] == f'{last_day_known} {hour}:00:00'][keys]).copy()\n",
    "            # timestamp = datetime.strptime(f\"{d} {h}:00:00\", date_format)\n",
    "        last_len = len(X_te_est_a_[h]) \n",
    "        # print(X_te_est_a_[h], last_values)\n",
    "        # X_te_est_a_[h] = pd.concat([X_te_est_a_[h], last_values], ignore_index=True)\n",
    "        print('ici ->', X_te_est_a_[h].columns, last_values.columns)\n",
    "        X_te_est_a_[h] = X_te_est_a_[h].append(last_values)\n",
    "        \n",
    "    # X_te_est_a_[h]['date_forecast'] = pd.to_datetime(X_te_est_a_[h]['date_forecast'])\n",
    "    X_te_est_a_[h] = X_te_est_a_[h].sort_values(by='date_forecast')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_te_est_a_[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_values = X_te_est_a_[23][X_te_est_a_[23]['date_forecast'] == '2023-05-01 23:00:00'][keys]\n",
    "last_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_values = X_te_est_a_[h][X_te_est_a_[h]['date_forecast'] == f'{last_day_known} {hour}:00:00'][keys]\n",
    "\n",
    "last_values, last_day_known, hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_te_est_a_[23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = ['2019', '2020', '2021', '2022']\n",
    "Xtr = { y: { h: X_tr_obs_a_[h][((X_tr_obs_a_[h]['date_forecast'] > f\"{y}-04-30\") & (X_tr_obs_a_[h]['date_forecast'] < f\"{y}-09-20\"))][keys] for h in range(24)} for y in years}\n",
    "\n",
    "for k in keys:\n",
    "    plt.figure(figsize=(20,8))\n",
    "    for y in years:\n",
    "        plt.plot(np.array(X_te_est_a[h][k]) - np.array(Xtr[y][13][k]), label=y)\n",
    "    plt.grid()\n",
    "    plt.title(k)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_a_mn['y'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_a_mn[train_a_mn['ds'].dt.strftime('%H:%M:%S').str.endswith('12:00:00') & train_a_mn['y'] == train_a_mn['y'].min()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_a[(train_a['time'].dt.strftime('%H:%M:%S').str.endswith('12:00:00')) & (train_a['pv_measurement'] == 0.0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(50, 12))\n",
    "for h in range(24):\n",
    "    # print(\"hour:\", h)\n",
    "    plt.subplot(6, 4, h + 1)\n",
    "    md.plot_normal_distribution(y_tr_a_[h]['y'], y_tr_a_[h]['y'].mean(), y_tr_a_[h]['y'].std())\n",
    "    plt.title(f\"Hour = {h}\")\n",
    "    plt.grid()\n",
    "\n",
    "plt.subplots_adjust(top=1., hspace=.9)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "donnees = y_tr_a_[13]['y']\n",
    "\n",
    "plt.hist(donnees, bins=20, density=True, alpha=0.6, color='b')\n",
    "plt.title(\"Distribution de données\")\n",
    "\n",
    "mu, sigma = np.mean(donnees), np.std(donnees)\n",
    "x = np.linspace(min(donnees), max(donnees), 100)\n",
    "pdf_normal = stats.norm.pdf(x, mu, sigma)\n",
    "\n",
    "plt.plot(x, pdf_normal, 'r-', label='Loi normale')\n",
    "\n",
    "# Ajustez une distribution de Poisson\n",
    "lambda_poisson = mu\n",
    "pdf_poisson = stats.poisson.pmf(np.arange(0, max(donnees) + 1), lambda_poisson)\n",
    "\n",
    "plt.plot(np.arange(0, max(donnees) + 1), pdf_poisson, 'g-', label='Loi de Poisson')\n",
    "\n",
    "# # Ajustez une distribution exponentielle\n",
    "# beta_exponentielle = 1 / mu\n",
    "# pdf_exponentielle = stats.expon.pdf(x, scale=1/beta_exponentielle)\n",
    "\n",
    "# plt.plot(x, pdf_exponentielle, 'b-', label='Loi exponentielle')\n",
    "\n",
    "\n",
    "# Ajustez une loi de Bernoulli\n",
    "# p_ber = 0.2  # Probabilité de succès\n",
    "# rv_ber = stats.bernoulli(p_ber)\n",
    "# x_ber = [0, 1]\n",
    "# plt.vlines(x_ber, 0, rv_ber.pmf(x_ber), colors='r', lw=5, label='Loi de Bernoulli')\n",
    "\n",
    "# Ajustez une loi binomiale\n",
    "n_binom = 4 # donnees.max() # 10  # Nombre d'essais\n",
    "p_binom = 0.3  # Probabilité de succès\n",
    "rv_binom = stats.binom(n_binom, p_binom)\n",
    "x_binom = np.arange(0, 11)\n",
    "plt.vlines(x_binom, 0, rv_binom.pmf(x_binom), colors='g', lw=5, label='Loi binomiale')\n",
    "\n",
    "# Ajustez une loi exponentielle\n",
    "lambda_exp = 1 / np.mean(donnees)  # Taux (inverse de la moyenne)\n",
    "x_exp = np.linspace(0, max(donnees), 100)\n",
    "pdf_exp = stats.expon.pdf(x_exp, scale=1/lambda_exp)\n",
    "plt.plot(x_exp, pdf_exp, 'c', label='Loi exponentielle')\n",
    "\n",
    "# # Ajustez une loi de Weibull\n",
    "# c_weibull = 2  # Paramètre de forme\n",
    "# lambda_weibull = np.mean(donnees)  # Paramètre d'échelle\n",
    "# x_weibull = np.linspace(0, max(donnees), 100)\n",
    "# pdf_weibull = stats.exponweib.pdf(x_weibull, c_weibull, scale=lambda_weibull)\n",
    "# plt.plot(x_weibull, pdf_weibull, 'm', label='Loi de Weibull')\n",
    "\n",
    "# Ajustez une loi de Weibull\n",
    "c_weibull = 2  # Paramètre de forme\n",
    "lambda_weibull = np.mean(donnees)  # Paramètre d'échelle\n",
    "x_weibull = np.linspace(0, max(donnees), 100)\n",
    "pdf_weibull = stats.weibull_min.pdf(x_weibull, c_weibull, scale=lambda_weibull)\n",
    "plt.plot(x_weibull, pdf_weibull, 'm', label='Loi de Weibull')\n",
    "\n",
    "\n",
    "# Ajustez une loi de Pareto\n",
    "alpha_pareto = 2.5  # Index de forme\n",
    "xm_pareto = np.min(donnees)  # Échelle minimale\n",
    "x_pareto = np.linspace(min(donnees), max(donnees), 100)\n",
    "pdf_pareto = stats.pareto.pdf(x_pareto, alpha_pareto, scale=xm_pareto)\n",
    "plt.plot(x_pareto, pdf_pareto, 'y', label='Loi de Pareto')\n",
    "\n",
    "# Ajustez une loi log-normale\n",
    "mu_ln = np.log(np.mean(donnees)) - 0.5 * np.var(np.log(donnees))\n",
    "sigma_ln = np.sqrt(np.var(np.log(donnees)))\n",
    "x_ln = np.linspace(0, max(donnees), 100)\n",
    "pdf_ln = stats.lognorm.pdf(x_ln, sigma_ln, scale=np.exp(mu_ln))\n",
    "plt.plot(x_ln, pdf_ln, 'k', label='Loi log-normale')\n",
    "\n",
    "# Ajustez une loi de Cauchy\n",
    "x0_cauchy = np.median(donnees)  # Médiane\n",
    "gamma_cauchy = np.std(donnees)  # Largeur à mi-hauteur\n",
    "x_cauchy = np.linspace(min(donnees), max(donnees), 100)\n",
    "pdf_cauchy = stats.cauchy.pdf(x_cauchy, x0_cauchy, gamma_cauchy)\n",
    "plt.plot(x_cauchy, pdf_cauchy, 'r', label='Loi de Cauchy')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "donnees = (y_tr_a_[13]['y'] - y_tr_a_[13]['y'].mean()) / y_tr_a_[13]['y'].std() + 2 # y_tr_a_[13]['y'].min()\n",
    "for k in range(101): \n",
    "    plt.figure(figsize=(10,8))\n",
    "    plt.hist(donnees, bins=20, density=True, alpha=0.6, color='b')\n",
    "    n_binom = 4 # donnees.max() # 10  # Nombre d'essais\n",
    "    p_binom = k * 1e-2  # Probabilité de succès\n",
    "    rv_binom = stats.binom(n_binom, p_binom)\n",
    "    x_binom = np.arange(0, 11)\n",
    "    plt.vlines(x_binom, 0, rv_binom.pmf(x_binom), colors='g', lw=5, label='Loi binomiale')\n",
    "    plt.title(f\"Bernoulli p={p_binom}\")\n",
    "    plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in keys:\n",
    "    plt.figure(figsize=(50, 12))\n",
    "    for h in range(24):\n",
    "        # print(\"hour:\", h)\n",
    "        plt.subplot(6, 4, h + 1)\n",
    "        md.plot_normal_distribution(X_tr_obs_a_[h][k], X_tr_obs_a_[h][k].mean(), X_tr_obs_a_[h][k].std())\n",
    "        plt.title(f\"Hour = {h}\")\n",
    "        plt.grid()\n",
    "\n",
    "    plt.suptitle(f'key = {k}', y=0)\n",
    "    plt.subplots_adjust(top=1., hspace=.9)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlsolar",
   "language": "python",
   "name": "mlsolar"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
