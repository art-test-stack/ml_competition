{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Data analysis"
      ],
      "metadata": {
        "id": "gfZ_UR0JXVo9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Overview of Datas"
      ],
      "metadata": {
        "id": "IylJ7kNzX-si"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "In this section, we'll get to grips with the data and begin to understand its structure, what it's all about, and so on...\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "fMc4N8L9YSyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "File dimensions\n",
        "\n"
      ],
      "metadata": {
        "id": "Fva__L-QYdoy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_a.shape,train_b.shape,train_c.shape)"
      ],
      "metadata": {
        "id": "V4Ge5b9SYrZO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dimensions of train_a, train_b and train_c are (34085, 2) (32848, 2) (32155, 2);"
      ],
      "metadata": {
        "id": "2AXRcJ93c_fG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train_estimated_a.shape,X_train_estimated_b.shape,X_train_estimated_c.shape)"
      ],
      "metadata": {
        "id": "yo3xCIR7Zab5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dimensions of X_train_estimated_a, X_train_estimated_b and X_train_estimated_c are (17576, 47) (17576, 47) (17576, 47)."
      ],
      "metadata": {
        "id": "SHSsfShfdV67"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train_observed_a.shape,X_train_observed_b.shape,X_train_observed_c.shape)"
      ],
      "metadata": {
        "id": "-EUfWNRyZaiz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dimensions of X_train_observed_a, X_train_observed_b and X_train_observed_c are (118669, 46) (116929, 46) (116825, 46)."
      ],
      "metadata": {
        "id": "9OY1Q-utdWu-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train_estimated_a.shape,X_train_estimated_b.shape,X_train_estimated_c.shape)"
      ],
      "metadata": {
        "id": "FdfaCWcsZani"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dimensions of X_train_estimated_a, X_train_estimated_b and X_train_estimated_b are (17576, 47) (17576, 47) (17576, 47)."
      ],
      "metadata": {
        "id": "u9mgyGsYdXsT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We observe that X_train_estimated and X_test_estimated has one more column than X_test_observed which is date_calc"
      ],
      "metadata": {
        "id": "KedcH3w3auQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Look at the variable types"
      ],
      "metadata": {
        "id": "JvnSkZd8aYle"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_estimated_a.dtypes"
      ],
      "metadata": {
        "id": "FvhnYa70ad1F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_estimated_a.dtypes"
      ],
      "metadata": {
        "id": "sKRZXsKVhMiw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_observed_a.dtypes"
      ],
      "metadata": {
        "id": "xHumuigdh1qf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We look at the start and end dates of the files"
      ],
      "metadata": {
        "id": "Gr_xJRz-aeRc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train_observed_a['date_forecast'].min(), X_train_observed_a['date_forecast'].max())\n",
        "print(X_train_estimated_a['date_forecast'].min(), X_train_estimated_a['date_forecast'].max())\n",
        "print(X_train_observed_b['date_forecast'].min(), X_train_observed_b['date_forecast'].max())\n",
        "print(X_train_estimated_b['date_forecast'].min(), X_train_estimated_b['date_forecast'].max())\n",
        "print(X_train_observed_c['date_forecast'].min(), X_train_observed_c['date_forecast'].max())\n",
        "print(X_train_estimated_c['date_forecast'].min(), X_train_estimated_c['date_forecast'].max())"
      ],
      "metadata": {
        "id": "DwGLAYCPjxj6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Nan Study"
      ],
      "metadata": {
        "id": "_lo5cDFZkNaY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we'll see how our missing data is distributed, so that we can deal with this problem later."
      ],
      "metadata": {
        "id": "c616EO8Uko-m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gives the proportion of missing values for each column in the DataFrame, sorted from highest to lowest, as a percentage of the total number of rows in the DataFrame."
      ],
      "metadata": {
        "id": "yYPFKqDtydHc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_estimated_a.isna().sum().sort_values(ascending=False)/(len(X_train_estimated_a))"
      ],
      "metadata": {
        "id": "CJEQN3nGkZDn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_estimated_a.isna().sum().sort_values(ascending=False)/(len(X_test_estimated_a))"
      ],
      "metadata": {
        "id": "mTdoXRxPlFz9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_observed_a.isna().sum().sort_values(ascending=False)/(len(X_train_observed_a))"
      ],
      "metadata": {
        "id": "861w-j1PmLvn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_estimated_b.isna().sum().sort_values(ascending=False)/(len(X_train_estimated_b))"
      ],
      "metadata": {
        "id": "U4icAXSVsnXR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_estimated_b.isna().sum().sort_values(ascending=False)/(len(X_test_estimated_b))"
      ],
      "metadata": {
        "id": "QAdzzxnvsnpG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_observed_b.isna().sum().sort_values(ascending=False)/(len(X_train_observed_b))"
      ],
      "metadata": {
        "id": "3b_r_A6tsnz8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_estimated_c.isna().sum().sort_values(ascending=False)/(len(X_train_estimated_c))"
      ],
      "metadata": {
        "id": "k9KFLW17s0a0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_estimated_c.isna().sum().sort_values(ascending=False)/(len(X_test_estimated_c))"
      ],
      "metadata": {
        "id": "Z1vMyn-Gs0lk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_observed_c.isna().sum().sort_values(ascending=False)/(len(X_train_observed_c))"
      ],
      "metadata": {
        "id": "fvYzuLmcs0s1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We notice that the columns with NAN values are snow_density, ceiling_height_agl and cloud_base_agl."
      ],
      "metadata": {
        "id": "dFMm3gyqwnZY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Study of the target"
      ],
      "metadata": {
        "id": "3ddKaEHKtbcF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We study the target to see how it evolves over time. If there is information to be deduced that our model will need to understand and use to make its predictions"
      ],
      "metadata": {
        "id": "8nwMAo1htoqA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Show variables for 3 locations\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "m4WuHbOauIuv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#show the variable pv_measurement as a functio of time\n",
        "fig, axs = plt.subplots(3, 1, figsize=(30, 20), sharex=True)\n",
        "\n",
        "train_a[['time','pv_measurement']].set_index('time').plot(ax=axs[0], title='pv_measurement on location A')\n",
        "train_b[['time','pv_measurement']].set_index('time').plot(ax=axs[1], title='pv_measurement on location B')\n",
        "train_c[['time','pv_measurement']].set_index('time').plot(ax=axs[2], title='pv_measurement on location C')"
      ],
      "metadata": {
        "id": "XrRT5bInvNeh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## périodicité a compléter\n"
      ],
      "metadata": {
        "id": "_vB4nk_dzapu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our data show periodicities. In section 2.1.Signal analysis we have noticed 3 main frequencies: the year, the day and 12h."
      ],
      "metadata": {
        "id": "Z-4W35lazdb9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Relever les variations un peu hasardeuse ou complexe à prévoir à l'oeil nue A compléter\n",
        "\n"
      ],
      "metadata": {
        "id": "eAaav2DJ7IRE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## corrélation entre les 3 lieux A complété"
      ],
      "metadata": {
        "id": "oMKgn7LKymRe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comparaison entre variable"
      ],
      "metadata": {
        "id": "-CVH5qbv7_mn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler_a = MinMaxScaler()\n",
        "scaler_b = MinMaxScaler()\n",
        "scaler_c = MinMaxScaler()"
      ],
      "metadata": {
        "id": "gWN6GdMND7Qa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_a_to_analyse = X_train_observed_a.drop(columns='date_forecast', inplace=False)\n",
        "X_b_to_analyse = X_train_observed_b.drop(columns='date_forecast', inplace=False)\n",
        "X_c_to_analyse = X_train_observed_c.drop(columns='date_forecast', inplace=False)\n"
      ],
      "metadata": {
        "id": "9RY9ARTUu_Zl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns_match_already_done = []"
      ],
      "metadata": {
        "id": "KAM7kGL-u_vv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_a_normed = scaler_a.fit_transform(X_a_to_analyse)\n",
        "X_b_normed = scaler_b.fit_transform(X_b_to_analyse)\n",
        "X_c_normed = scaler_c.fit_transform(X_c_to_analyse)"
      ],
      "metadata": {
        "id": "GXaq_DNRPAZ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns = list(X_a_to_analyse.columns.values)"
      ],
      "metadata": {
        "id": "k8i3kfCaOztM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns_to_plot = [(\"dew_point_2m:K\",\"absolute_humidity_2m:gm3\"),\n",
        "                   (\"elevation:m\",\"absolute_humidity_2m:gm3\"),\n",
        "                   (\"elevation:m\",\"msl_pressure:hPa\"),\n",
        "                   (\"elevation:m\",\"relative_humidity_1000hPa:p\"),\n",
        "                   (\"elevation:m\",\"snow_density:kgm3\"),\n",
        "                   (\"elevation:m\",\"snow_water:kgm2\"),\n",
        "                   (\"elevation:m\",\"sun_azimuth:d\"),\n",
        "                   (\"elevation:m\",\"super_cooled_liquid_water:kgm2\"),\n",
        "                   (\"elevation:m\" ,\"t_1000hPa:K\"),\n",
        "                   (\"msl_pressure:hPa\",\"pressure_100m:hPa\"),\n",
        "                   (\"msl_pressure:hPa\",\"sfc_pressure:hPa\"),\n",
        "                   (\"pressure_100m:hPa\",\"sfc_pressure:hPa\"),\n",
        "                   (\"pressure_50m:hPa\",\"relative_humidity_1000hPa:p\"),\n",
        "                   (\"sun_azimuth:d\",\"total_cloud_cover:p\")\n",
        "                  ]"
      ],
      "metadata": {
        "id": "5sCm-vh1O3xH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for pair in columns_to_plot:\n",
        "    c1, c2 = pair\n",
        "    c1_index = columns.index(c1)\n",
        "    c2_index = columns.index(c2)\n",
        "    plt.scatter(X_a_normed[:, c2_index], X_a_normed[:, c1_index], alpha=0.5)\n",
        "    plt.scatter(X_b_normed[:, c2_index], X_b_normed[:, c1_index], alpha=0.3)\n",
        "    plt.scatter(X_c_normed[:, c2_index], X_c_normed[:, c1_index], alpha=0.1)\n",
        "    plt.xlabel(c1)\n",
        "    plt.ylabel(c2)\n",
        "    plt.grid()\n",
        "    plt.show()\n",
        "    print(\"Compare\", c1, c2)\n",
        "    columns_match_already_done.append((c1, c2))\n",
        "    columns_match_already_done.append((c2, c1))"
      ],
      "metadata": {
        "id": "Oaz7tGz9vD6J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "auxlvGmBvFdj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CrBoyUL5vYm9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "rA5KRM5nvroF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-PRqiyFvwd01"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "odk5tWRbwXZR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zLXSAnr-wnzw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vB53wk1EwqV8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T1OVk4RVwtmp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Correlation study"
      ],
      "metadata": {
        "id": "rDq045mx8C9G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "With the help of the correlation matrices, we can begin to study the relationships between the different variables in order to potentially distinguish groups, or other features of our dataset."
      ],
      "metadata": {
        "id": "7cWah89F8JA9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "An example of a correlation matrix\n"
      ],
      "metadata": {
        "id": "Hxs2zp2-8Jx-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "keys = [1, 2, 3]"
      ],
      "metadata": {
        "id": "IMwCeQPCNguz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "frames_train_estimated = [X_train_estimated_a.drop(columns=[\"date_calc\"]), X_train_observed_a, X_test_estimated_a.drop(columns=[\"date_calc\"])]\n",
        "X_frames_a = pd.concat(frames_train_estimated, keys=keys)\n",
        "X_frames_a.reset_index(level=0, inplace=True, names='frame_type')\n",
        "\n",
        "train_a = train_a.rename(columns={'time': 'date_forecast'})\n",
        "X_y_a = X_frames_a.merge(train_a, on='date_forecast', how='inner')\n",
        "X_y_a.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "id": "QAX16xYqJhZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "utils.build_corr_matrix(X_y_a, figsize=(50,50))"
      ],
      "metadata": {
        "id": "F85Yr5tJASF3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The most correlated variables for pv_measurement are :\n",
        "\n",
        "*   clear_sky_energy_1h:J: clear sky energy of previous time period, available up to 24h [J/m2]\n",
        "*   clear_sky_rad:W: clear sky radiation flux [W/m2]\n",
        "*   diffuse_rad:W: diffuse radiation flux [W/m2]\n",
        "*   diffuse_rad_1h:J:\n",
        "*   direct_rad:W: direct radiation flux [W/m2]"
      ],
      "metadata": {
        "id": "tOJ24c7aNsLA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "frames_train_estimated = [X_train_estimated_b.drop(columns=[\"date_calc\"]), X_train_observed_b, X_test_estimated_b.drop(columns=[\"date_calc\"])]\n",
        "X_frames_b = pd.concat(frames_train_estimated, keys=keys)\n",
        "X_frames_b.reset_index(level=0, inplace=True, names='frame_type')\n",
        "\n",
        "train_b = train_b.rename(columns={'time': 'date_forecast'})\n",
        "X_y_b = X_frames_b.merge(train_b.dropna(), on='date_forecast', how='inner')\n",
        "X_y_b.reset_index(drop=True, inplace=True)\n",
        "\n",
        "frames_train_estimated = [X_train_estimated_c.drop(columns=[\"date_calc\"]), X_train_observed_c, X_test_estimated_c.drop(columns=[\"date_calc\"])]\n",
        "X_frames_c = pd.concat(frames_train_estimated, keys=keys)\n",
        "X_frames_c.reset_index(level=0, inplace=True, names='frame_type')\n",
        "\n",
        "train_c = train_c.rename(columns={'time': 'date_forecast'})\n",
        "X_y_c = X_frames_c.merge(train_c.dropna(), on='date_forecast', how='inner')\n",
        "X_y_c.reset_index(drop=True, inplace=True)\n",
        "\n",
        "frames_location= [X_y_a, X_y_b, X_y_c]\n",
        "X_y = pd.concat(frames_location, keys=keys)\n",
        "X_y.reset_index(level=0, inplace=True, names='location')"
      ],
      "metadata": {
        "id": "8gfB-TJqAV-R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "utils.build_corr_matrix(X_y, figsize=(50,50))"
      ],
      "metadata": {
        "id": "KrL76f5-MUqL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "3EuC0Df6AXil"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Mettre les résultats (groupement de var par exemple)\n"
      ],
      "metadata": {
        "id": "LYlDHFLv8L9B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "frames_train_estimated = [X_train_estimated_a, X_train_estimated_b, X_train_estimated_c]\n",
        "X_train_estimated = pd.concat(frames_train_estimated, keys=keys)\n",
        "X_train_estimated.reset_index(level=0, inplace=True, names='location')\n",
        "\n",
        "frames_train_observed = [X_train_observed_a, X_train_observed_b, X_train_observed_c]\n",
        "X_train_observed = pd.concat(frames_train_observed, keys=keys)\n",
        "X_train_observed.reset_index(level=0, inplace=True, names='location')\n",
        "\n",
        "frames_test_estimated = [X_test_estimated_a, X_test_estimated_b, X_test_estimated_c]\n",
        "X_test_estimated = pd.concat(frames_test_estimated, keys=keys)\n",
        "X_test_estimated.reset_index(level=0, inplace=True, names='location')"
      ],
      "metadata": {
        "id": "x5I0TcaHT08Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_estimated_merged = pd.concat(frames_train_estimated, axis=1)\n",
        "X_train_estimated_merged.reset_index(drop=True, inplace=True)\n",
        "\n",
        "X_train_observed_merged = pd.concat(frames_train_observed, axis=1)\n",
        "X_train_observed_merged.reset_index(drop=True, inplace=True)\n",
        "\n",
        "X_test_estimated_merged = pd.concat(frames_test_estimated, axis=1)\n",
        "X_test_estimated_merged.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "id": "zyHY7pZ9T1Dq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_estimated_merged = pd.concat(frames_train_estimated, axis=1)\n",
        "X_train_estimated_merged.reset_index(drop=True, inplace=True)\n",
        "\n",
        "X_train_observed_merged = pd.concat(frames_train_observed, axis=1)\n",
        "X_train_observed_merged.reset_index(drop=True, inplace=True)\n",
        "\n",
        "X_test_estimated_merged = pd.concat(frames_test_estimated, axis=1)\n",
        "X_test_estimated_merged.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "id": "t8ENylHvT1Ij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_corr_matrix(data_frames, figsize=(20,20), annot=True):\n",
        "    plt.figure(figsize=figsize)\n",
        "    sns.heatmap(data_frames.corr(method='pearson'), annot=annot, cmap=plt.cm.Reds)"
      ],
      "metadata": {
        "id": "-27h3yy3T1L3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we look at the correlation matrix of [X_train_estimated_abc]:"
      ],
      "metadata": {
        "id": "EjhaXfahVOTg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "build_corr_matrix(X_train_estimated_merged, figsize=(100,100), annot=True)"
      ],
      "metadata": {
        "id": "BCnukBU8Tvde"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Var and target correlation study as a function of quarter-hours\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4pG5H0pV8ONU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calcul_decalage(decalage=0):\n",
        "  train_a_travail = train_a.copy()\n",
        "  X = X_train_observed_a.copy()\n",
        "  train_a_travail.rename(columns={'time': 'date_forecast'}, inplace=True)\n",
        "  train_a_travail[\"date_forecast\"] = pd.to_numeric(train_a_travail['date_forecast'], errors='coerce')\n",
        "  X[\"date_forecast\"] = pd.to_numeric(X['date_forecast'], errors='coerce')\n",
        "  dec = 900000000000\n",
        "  train_a_travail['date_forecast'] = train_a_travail['date_forecast'].apply(lambda x: float(x) + dec*decalage)  #15min en nanoseconde\n",
        "  X['date_forecast'] = X['date_forecast'].apply(lambda x: float(x))\n",
        "  merged_df_a = pd.merge(X, train_a_travail, on='date_forecast', how='inner')\n",
        "  return merged_df_a.corr()[\"pv_measurement\"]"
      ],
      "metadata": {
        "id": "OaL8GWoK8VG-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correlations_0 = calcul_decalage(decalage=0)"
      ],
      "metadata": {
        "id": "d3peCWCzRwMn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a bar graph to visualize correlations\n",
        "plt.figure(figsize=(50, 30))\n",
        "sns.barplot(x=correlations_0.index[:-3], y=correlations_0.values[:-3])\n",
        "plt.xlabel(\"Colonnes\")\n",
        "plt.ylabel(f\"Corrélation avec \")\n",
        "plt.title(f\"Corrélations avec \"+\"correlations_0 \")\n",
        "plt.xticks(rotation=90)\n",
        "plt.ylim(-1,1)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wrFwFQ0OR0oH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A rajouter"
      ],
      "metadata": {
        "id": "KD7uTsa_0Ih3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   Search domain knowledge\n",
        "*   Check if the data is intuitive\n",
        "*   Understand how the data was generated\n",
        "*   Explore individual features\n",
        "*   Explore pairs and groups of features\n",
        "*   Clean up features"
      ],
      "metadata": {
        "id": "HWRacB0X0LIe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Separation of train and test set"
      ],
      "metadata": {
        "id": "kAJVRuCAmvpE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "V1: separation with a fixed date"
      ],
      "metadata": {
        "id": "iSY5HONxm2Ro"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "split_date_a = pd.to_datetime(\"2023-02-01\")"
      ],
      "metadata": {
        "id": "KOF3mWgkqYfh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pv_train_a = X_total_a_y_nan[X_total_a_y_nan['date_forecast'] <= split_date_a].copy()\n",
        "pv_test_a = X_total_a_y_nan[X_total_a_y_nan['date_forecast'] > split_date_a].copy()\n",
        "\n",
        "pv_train_b = X_total_b_y_nan[X_total_b_y_nan['date_forecast'] <= split_date_a].copy()\n",
        "pv_test_b = X_total_b_y_nan[X_total_b_y_nan['date_forecast'] > split_date_a].copy()\n",
        "\n",
        "pv_train_c = X_total_c_y_nan[X_total_c_y_nan['date_forecast'] <= split_date_a].copy()\n",
        "pv_test_c = X_total_c_y_nan[X_total_c_y_nan['date_forecast'] > split_date_a].copy()"
      ],
      "metadata": {
        "id": "O82_ENGhyanX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_ = pv_test_a \\\n",
        "    .rename(columns={'pv_measurement': 'TEST SET'}) \\\n",
        "    .join(pv_train_a.rename(columns={'pv_measurement': 'TRAINING SET'}), how='outer') \\\n",
        "    .plot(figsize=(15,5), title='pv_measurement', style='')\n",
        "\n",
        "_ = pv_test_b \\\n",
        "    .rename(columns={'pv_measurement': 'TEST SET'}) \\\n",
        "    .join(pv_train_b.rename(columns={'pv_measurement': 'TRAINING SET'}), how='outer') \\\n",
        "    .plot(figsize=(15,5), title='pv_measurement', style='')\n",
        "\n",
        "_ = pv_test_c \\\n",
        "    .rename(columns={'pv_measurement': 'TEST SET'}) \\\n",
        "    .join(pv_train_c.rename(columns={'pv_measurement': 'TRAINING SET'}), how='outer') \\\n",
        "    .plot(figsize=(15,5), title='pv_measurement', style='')"
      ],
      "metadata": {
        "id": "h7tP0aDqya1J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Post-processing"
      ],
      "metadata": {
        "id": "qCs1y16hPkAJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we'll make sure we only have positive values"
      ],
      "metadata": {
        "id": "PGAPsXzlP4SD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result = np.concatenate((np.concatenate((result_A,result_B)), result_C))"
      ],
      "metadata": {
        "id": "9ECTnnSeQaDr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "negative_mask = result < 0\n",
        "result[negative_mask] = 0"
      ],
      "metadata": {
        "id": "xyYA9EyIQkhh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}